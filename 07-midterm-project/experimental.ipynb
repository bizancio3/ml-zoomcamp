{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(\"water_potability.csv\")\n",
    "df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking data types\n",
    "df_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing data\n",
    "df_raw.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=df_raw[\"Potability\"])\n",
    "print(f'{df_raw.Potability[df_raw.Potability==1].count()/df_raw.Potability.count()*100:.2f} % of samples are potable (1)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix for dataset\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.heatmap(df_raw.corr(), annot=True, cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of features\n",
    "potable = df_raw.query('Potability == 0')\n",
    "not_potable = df_raw.query('Potability == 1')\n",
    "\n",
    "fig = plt.figure(figsize=(20,15))\n",
    "\n",
    "for ax,column in enumerate(df_raw.columns[:9]):\n",
    "    plt.subplot(3,3,ax+1)\n",
    "    plt.title(f'Distribution of {column} values')\n",
    "    sns.kdeplot(x=not_potable[column],label='Not Potable(0)')\n",
    "    sns.kdeplot(x=potable[column],label='Potable(1)')\n",
    "    plt.legend(prop=dict(size=10))\n",
    "\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputing missing data\n",
    "\n",
    "def fill_nan(df):\n",
    "    for index, column in enumerate(df.columns[:9]):\n",
    "        # print(index, column)\n",
    "        df[column] = df[column].fillna(df.groupby('Potability')[column].transform('mean'))\n",
    "    return df\n",
    "        \n",
    "df = fill_nan(df_raw)\n",
    "\n",
    "df.isna().sum()                                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting\n",
    "X = df.drop(['Potability'], axis = 1)\n",
    "y = df['Potability']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.25, random_state=18, stratify=y) #stratify=y\n",
    "\n",
    "# Balancing data - oversampling minority\n",
    "smt = SMOTE()\n",
    "X_train, y_train = smt.fit_resample(X_train, y_train)\n",
    "\n",
    "# Scaling\n",
    "sc = StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put models in a dictionary\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(), \n",
    "    \"Random Forest\": RandomForestClassifier(),                  \n",
    "    \"XgBoost\": XGBClassifier(),\n",
    "    \"CatBoost Classifier\": CatBoostClassifier()\n",
    "}\n",
    "\n",
    "# Create a function to fit and score models\n",
    "def fit_and_score(models, X_train, X_test, y_train, y_test):\n",
    "   \n",
    "    \"\"\"\n",
    "   Fits and evaluates given machine learning models.\n",
    "   models: a dict of different Scikit_Learn machine learning models\n",
    "   X_train: training data (no labels)\n",
    "   X_test: testing data (no labels)\n",
    "   y_train: training labels\n",
    "   y_test: test labels\n",
    "   \"\"\" \n",
    "    # Set random seed\n",
    "    np.random.seed(18)\n",
    "    # Make a dictionary to keep model scores\n",
    "    model_scores = {}\n",
    "    # Loop through models\n",
    "    for name, model in models.items():\n",
    "        # Fit model to data\n",
    "        model.fit(X_train, y_train)\n",
    "        # Evaluate model and append its score to model_scores\n",
    "        model_scores[name] = cross_val_score(model,\n",
    "                                             X_test,\n",
    "                                             y_test,\n",
    "                                            scoring='roc_auc',\n",
    "                                            cv=5\n",
    "                                            ).mean()\n",
    "\n",
    "    return model_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scores = fit_and_score(models,X_train,X_test,y_train,y_test)\n",
    "\n",
    "model_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The XGB Classifier seems to show the most promise \n",
    "# with about 79% accuracy after 5 folds of cross-validation\n",
    "\n",
    "model_compare = pd.DataFrame(model_scores, index=[\"roc_auc\"])\n",
    "model_compare.T.plot.bar(color=\"green\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "np.random.seed(18)\n",
    "\n",
    "# Create a hyperparameter grid for XGB Classifier\n",
    "xgb_grid = {\n",
    "    \"learning_rate\" : [0.01, 0.05, 0.10, 0.20, 0.30],\n",
    "    \"n_estimators\" : [50, 100, 200, 500, 1000],\n",
    "    \"max_depth\" : [ 3, 5, 8, 11, 15],\n",
    "    \"min_child_weight\" : [ 1, 3, 5, 7, 10]\n",
    "}\n",
    "\n",
    "\n",
    "# Setup random hyperparameter search for XGB Classifier\n",
    "rs_xgb = RandomizedSearchCV(XGBClassifier(),\n",
    "                                param_distributions=xgb_grid,\n",
    "                                cv=2,\n",
    "                                n_iter=100,\n",
    "                                verbose=0\n",
    "                               )\n",
    "\n",
    "# Fit random hyperparameter search model for XGB Classifier\n",
    "rs_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Find best hyperparamaters\n",
    "rs_xgb.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_xgb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final model - XGBClassifier\n",
    "\n",
    "model = XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate =0.2, \n",
    "    max_depth=8, \n",
    "    min_child_weight=10\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), \n",
    "    annot=True, \n",
    "    fmt='d', \n",
    "    cmap='YlGnBu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "\n",
    "def plot_features(columns, importances,n=20):\n",
    "    df = (pd.DataFrame({\"features\": columns,\n",
    "                       \"feature_importances\": importances})\n",
    "         .sort_values(\"feature_importances\", ascending=False)\n",
    "         .reset_index(drop=True))\n",
    "    # Plot dataframe\n",
    "    fix, ax = plt.subplots()\n",
    "    ax.barh(df[\"features\"][:n], df[\"feature_importances\"][:20])\n",
    "    ax.set_ylabel(\"Features\")\n",
    "    ax.set_xlabel(\"Feature Importance\")\n",
    "    ax.invert_yaxis()\n",
    "    \n",
    "plot_features(df.drop(['Potability'],axis=1).columns, model.feature_importances_)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
